---
title: "mnv_caller_cds_aligner"
author: "Haider Inam"
date: "12/28/2021"
output: html_document
---

```{r setup, include=FALSE}
# rm(list=ls())

knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
library(ggplot2)
library(plotly)
```
####This is the same aligner as mnv_caller_practice except I used it for processing the reads aligned to the abl1 kinase domain cds rather than hg38. 
####How does the different alignment change the analysis: 
-No L298L
-No split reads (spanning multiple exons), and hence no problems with the end of one exon being thought of as the beginning of the other exon
-Overall lower false negative mnv discovery rate

####Function that uses start and stop positions and returns sequence
```{r}
# getwd()
#Reading ABL1 sequence. Starts
abl1_seq=read.table("abl1_cds_kinasedomain.txt")
abl1_seq=as.character(abl1_seq)

# substr(abl1_seq,1,2)
abl1_search=function(start,stop){
  seachresult=substr(abl1_seq,start,stop-1)
  seachresult
}

abl_genomic_coordinates=read.csv("../Dunovo/abl1_kinasedomain_coordinates.csv",header = T,stringsAsFactors = F)
# abl_genomic_coordinates=abl_genomic_coordinates%>%dplyr::select(-X)

####Adding sequence to each codon###
abl_genomic_coordinates=abl_genomic_coordinates%>%
  rowwise()%>%
  mutate(codon=abl1_search(start,end+1))
```

####Function that returns the codon number given the genomic position
```{r}
ref_codon_finder=function(position){
  abl_genomic_coordinates$match=NA
  match=abl_genomic_coordinates$match

  for(i in 1:length(abl_genomic_coordinates$start)){
    match[i]=position>=abl_genomic_coordinates$start[i]&&position<=abl_genomic_coordinates$end[i]
  }
  if(TRUE%in%match){
    return(abl_genomic_coordinates[grep(TRUE,match),1])
  }
  # else{
    return(NaN)
  # }
}
# position=130835456
# (ref_codon_finder(130835456))
# ref_codon_finder(130854218)
# ref_codon_finder(130873014)

####To convert coordinates from ABL CDS e.g. (796-797A/G) to 1300000-130001A/G#####
# Inputs: input_df dataframe containing alt_start_pos, alt_end_pos
# Outputs: input_df with alt_start_hg38 and alt_end_hg38
#Dependencies: abl_genomic_coordinates dataframe
# i=1
cds_to_hg38=function(input_df){
  if(sum(as.numeric(grep("alt_end_ois",colnames(input_df))))==0){
  input_df$alt_end_pos=input_df$alt_start_pos+1
  #^basically saying that if you don't find a column called alt_end_hg38, make it
}
  input_df$alt_start_hg38=NA
  input_df$alt_end_hg38=NA
  for(i in 1:nrow(input_df)){
    abl_i=abl_genomic_coordinates
    abl_i$diff_start=input_df$alt_start_pos[i]-645-abl_i$start
    abl_i$diff_end=input_df$alt_end_pos[i]-645-abl_i$start
    abl_i=abl_i%>%filter(diff_start>=0)%>%arrange(diff_start)
    abl_i=abl_i[1,]
    input_df$alt_start_hg38[i]=abl_i$start_chr+abl_i$diff_start
    input_df$alt_end_hg38[i]=abl_i$start_chr+abl_i$diff_end
  }
  return(input_df)
}




```


####Functions to use Ensembl's VEP to find protein consequence of mutations.
```{r}


# The ensembl server where you can download multiple things from
# https://rest.ensembl.org/
# https://rest.ensembl.org/vep/human/region/9:130884090:130884091/A
library(httr)
library(jsonlite)
library(xml2)
# region="130862976:130862976/A"
# region="130854096:130854096/A" #splice variant
# region="130854240:130854240/G" #throws bad http error
# region="130854096:130854096/A" #first missense in dataset
# region="130872215:130872215/T"
# region="130863033:130863036/TAC"
# region="130872213..130872215/CAC"
# region="130872213..130872861/CAC"
# region="130875054:130875054/T"
# a=vep_fromquery(region)
vep_fromquery=function(region){
  #This function fetches ensembl vep for queries that look like this
  #Needs the packages httr, jsonlite, xml2
server <- "https://rest.ensembl.org"
ext=paste("/vep/human/region/9:",gsub("\"","",region),"?",sep = "")
# ext <- "/vep/human/region/9:130862976:130862976/A?"
 
r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
 
stop_for_status(r)
 
# use this if you get a simple nested list back, otherwise inspect its structure
rest_results=(fromJSON(toJSON(content(r))))
transcript_consequences=(rest_results$transcript_consequences)[[1]]
transcript_consequences=transcript_consequences%>%filter(transcript_id%in%"ENST00000318560")
transcript_consequences
}

```


```{r}
# a=snps_sum
# a=mnv_sum
# a=vep_fromdf(a)
# input_df=mutfile_splice 
# input_df=a
# input_df=input_df[-1,]
vep_fromdf=function(input_df){
  #Inputs: Dataframe with these fields: alt_start_hg38, alt
  #Optional field in dataframe: alt_end_hg38 (for mnvs because their end position is different than their starting position)
  #This function adds ensembl variant effect predictor annotations to dataframes.
  #This needs the vep_fromquery function
  #Requires the dplyr package
input_df=input_df%>%filter(!ref==alt)

input_df=input_df%>%mutate(protein_start=NA,protein_end=NA,amino_acids=NA,codons=NA,impact=NA,polyphen_prediction=NA,consequence_terms=NA)
# input_df=snps_sum
# input_df=mnv_sum
# i=1
      ###Can probably get rid of this clause because it appears in the cds_to_hg38 funciton.
      if(sum(as.numeric(grep("alt_end_hg38",colnames(input_df))))==0){
        input_df$alt_end_hg38=input_df$alt_start_hg38+1
        #^basically saying that if you don't find a column called alt_end_hg38, make it
}
# i=4
# for(i in 276:nrow(input_df)){
for(i in 1:nrow(input_df)){
  # i=63
  transcript_consequences=vep_fromquery(paste(input_df$alt_start_hg38[i],":",input_df$alt_end_hg38[i]-1,"/",input_df$alt[i],sep = ""))
  # b=vep_fromquery("130862936:130862938/TAA")
  # vep_fromquery("130874932:130874932/A")
  # transcript_consequences=vep_fromquery(paste(130884390,":",130884390,"/",input_df$alt[i],sep = ""))
  # transcript_consequences=vep_fromquery(paste(130862864,":",130862864,"/","C",sep = ""))
  # transcript_consequences$protein_start
  
  # if(grepl("splice|intron|stop",as.character(transcript_consequences$consequence_terms))%in%TRUE){
  if(grepl("intron|stop",as.character(transcript_consequences$consequence_terms))%in%TRUE){
    input_df$consequence_terms[i]=transcript_consequences$consequence_terms[[1]][1]
  }
  else{
    if("protein_start"%in%names(transcript_consequences)){
      input_df$protein_start[i]=transcript_consequences$protein_start[[1]][1]
    }
    if("protein_end"%in%names(transcript_consequences)){
      input_df$protein_end[i]=transcript_consequences$protein_end[[1]][1]
    }
    if("amino_acids"%in%names(transcript_consequences)){
      input_df$amino_acids[i]=transcript_consequences$amino_acids[[1]][1]
    }
    if("codons"%in%names(transcript_consequences)){
      input_df$codons[i]=transcript_consequences$codons[[1]][1]
    }
    if("impact"%in%names(transcript_consequences)){
      input_df$impact[i]=transcript_consequences$impact[[1]][1]
    }
    
    if(grepl("synonymous|frameshift",as.character(transcript_consequences$consequence_terms))%in%TRUE){
      input_df$polyphen_prediction[i]=NA
    }
    if(sum(as.numeric(grepl("polyphen_score",names(transcript_consequences))))==0){
      input_df$polyphen_prediction[i]=NA
    }
    # grepl("polyphen",names(transcript_consequences))%in%TRUE
    else{
      input_df$polyphen_prediction[i]=transcript_consequences$polyphen_prediction[[1]][1]  
    }
    
    input_df$consequence_terms[i]=transcript_consequences$consequence_terms[[1]][1]
    # transcript_consequences$consequence_terms[[1]][1]
  }
}
input_df
# a=snps_ann%>%filter(alt_start_hg38%in%"130874932")
}
```





```{r}
# library(dplyr)
setwd("~/OneDrive - The Pennsylvania State University/RProjects/duplex_sequencing_screen/data/Dunovo/Novogene_lane2/abl_ref/")
files=list.files(".")
#Grabbing only csvs that contain sorted and sscs in their name
files=files[grepl("*.tsv",files)]
# for(filecurr in 1:length(files)){
# skipped: #7 and 16, 19
for(filecurr in 1:length(files)){
  # filecurr=9
# for(filecurr in 9){
setwd("~/OneDrive - The Pennsylvania State University/RProjects/duplex_sequencing_screen/data/Dunovo/Novogene_lane2/abl_ref/")
setwd("~/OneDrive - The Pennsylvania State University/RProjects/duplex_sequencing_screen/data/Dunovo/Novogene_lane2/abl_ref/")

# alldata=read.table("d0_dcs_filtered_bigger.tsv",header = F,stringsAsFactors = F)
alldata=read.table("d0_sscs_filtered_cdna_aln.tsv",header = F,stringsAsFactors = F)
alldata=read.table("../../data/Dunovo/Novogene_lane7/5kmutants_100kfqlines/lane7_10m_filtered.tsv",header = F,stringsAsFactors = F)

alldata=read.table("../../data/Dunovo/sscs_dcs_comparisons/d2300_dcs_filtered.tsv",header = F,stringsAsFactors = F)

# rm(list=ls())
###This script looks at the a sam file, filters out non-reference, non-E255I, non-SNP. And makes two databases, one for mnvs and one for snps.
# alldata=read.table("filtered.tsv",header = F,stringsAsFactors = F)
# alldata=read.table("il3indep1_dcs_filtered.tsv",header = F,stringsAsFactors = F)
# alldata=read.table("il3indep1_sscs_filtered.tsv",header = F,stringsAsFactors = F)
# alldata=read.table("il3indep1_sscs_all_filtered.tsv",header = F,stringsAsFactors = F)
# alldata=read.table("il3indep1_dcs_all_filtered.tsv",header = F,stringsAsFactors = F)
# alldata=read.table("sor",header = F,stringsAsFactors = F)
names(alldata)=c("pos","cigar","tlen","seq","mdz")
# names(alldata)=c("flag","pos","mapq","cigar","tlen","seq","mdz")
alldata=alldata%>%mutate(mdz=gsub("MD:Z:","",mdz))


########Calculating Clip Distance for soft-clipped reads########
######Detecting soft-clipped reads and noting how many bases were soft clipped
#This is because the positions on the mdz field exclude the soft clipped portion of the read.
#The soft clipped reads that are relevant to us are reads in which the soft clip appears before the mismatch. b/c if a clip appears after a mismatch, that's the part of the mdz field that i don't care about. Therefore, I'm gonna care about those only. Btw only 1/3rd of soft clipped reads seem to have a clip followed by a mismatch.


alldata$soft_clipped=grepl("S.*M|M.*S",alldata$cigar)
###Filtering out reads that were soft clipped twice (all of those were mouse reads). Also figuring out the clipping distance for those with regexp is tougher.
alldata=alldata%>%filter(!grepl("(S.*){2}",cigar)%in%T)


alldata=alldata%>%
  rowwise()%>%
  mutate(clipdistance_left=case_when(soft_clipped%in%TRUE~strsplit(cigar,"S")[[1]][1],
                                TRUE~"0"))


alldata=alldata%>%
  mutate(right_clipped=case_when(grepl("M",clipdistance_left)%in%"TRUE"~T,
                                 T~F),
         clipdistance_right=case_when(right_clipped%in%T~as.numeric(strsplit(clipdistance_left,"M")[[1]][2]),
                                      T~0))

#Correcting the clip distance soft clips that are soft-clipped at the end of the read, and hence their clipped distance appears to be weird.
alldata$clipdistance_left[grepl("[A-Za-z]",alldata$clipdistance_left)]=0
alldata$clipdistance_left=as.numeric(alldata$clipdistance_left)
alldata$clipdistance_total=alldata$clipdistance_left+alldata$clipdistance_right

#####################Filtering Steps######################
#######Filtering soft clipped reads########
#When the reads are aligned to the CDS rather than to the hg38 genomic indices, there should be no clipping of reads (with genomic alignments you would expect tons of soft clipping to in the splice regions).
#How mouse reads were leaking into my variant caller by looking like clipped reads:
#Soft-clipped reads give us a good indication that reads are mouse reads. Most soft-clipped reads tend to be mouse, but not all mouse reads are soft-clipped. Soft-clipped mouse reads were annoying because they were the ones that ended up having short mdz fields (2-3 mismatches), whereas hypothetically no mouse read should have had <5 mismatches in a 133bp window.
#Can we just simply get rid of clipped reads? Most soft-clipped reads are mouse but not all. Some soft-clipped reads are human as well. In-fact, if we just simply get rid of the soft-clipped reads, they would be getting rid of 20% of human reads as well. While it's minor, we don't wanna just throw away 20%.
#Therefore, I looked at how human soft-clipped and mouse soft-clipped reads differ. Of the inconspicuous mouse reads (less than 5 mismatches), most of them are soft-clipped, and the legth of the read that is not clipped is much shorter than in human reads. In other words, the clipping distance (at the start or at the end of the read), is bigger in mouse reads than in human reads. 
#So we are going to filter out soft-clipped reads with a minimum clipping distance.

#We are also going to filter for reads with a minimum length of 80 (another way mouse reads can look like human reads by just being shorter).
alldata=alldata%>%mutate(seqlen=nchar(seq))%>%filter(seqlen>=90)
#We are also going to filter for reads with a clipping distance of less than 25
alldata=alldata%>%filter(clipdistance_total<=25)
#We are also going to filter for reads with a total length of mapped read >80. Mapped length is sequence length - length of split read
alldata=alldata%>%mutate(mlen=seqlen-clipdistance_total)%>%filter(mlen>=70)


#######Filtering out deletions########
alldata=alldata[!grepl("\\^",alldata$mdz),]

#####Filtering out any reads containing Ns####
# Gets rid of 10% of reads. This might be too stringent a filter because of course you would expect Ns in a 10bp window###
alldata=alldata[!grepl("N",alldata$seq),]

#######Filtering for Non-Reference########
# alt_positions=grepl("[0-9]{3}$",alldata$mdz)
alt_positions=grepl("[a-zA-Z]",alldata$mdz)
alldata=alldata[alt_positions,]

#######Filtering for Non-E255I########
# note255i_positions=!grepl("G0A0G",alldata$mdz)
# sum(as.numeric(note255i_positions))
# alldata=alldata[note255i_positions,]
#######Dividing SNPs and MNVs########
##########################SNPS########################################
snps=alldata%>%mutate(n_nuc=str_count(mdz,"A|T|C|G"))%>%filter(n_nuc==1)

snps=snps%>%rowwise()%>%mutate(alt_start_pos=pos+as.numeric(strsplit(mdz,"A|C|G|T")[[1]][1]),alt_end_pos=alt_start_pos+1)
snps=snps%>%
  # rowwise()%>%
  mutate(ref=abl1_search(alt_start_pos-645,alt_end_pos-645))

##Getting rid of mutants outside of the kinase domain. Do this for MNVs!!!##
snps=snps%>%filter(!ref%in%"")

###filtering out mismatches that are at the start or end of the read (and hence of the mdz field)###
#mut_extr aka mutations at the extremities of the read
snps=snps%>%
  rowwise()%>%
  mutate(mut_extr=
           case_when(as.numeric(strsplit(mdz,"A|C|G|T")[[1]][1])%in%c(0,1)~TRUE,
                     as.numeric(strsplit(mdz,"A|C|G|T")[[1]][2])%in%c(0,1)~TRUE,
                     TRUE~FALSE))
sum(as.numeric(snps$mut_extr))
snps=snps%>%filter(mut_extr%in%FALSE)


snps=snps%>%rowwise()%>%mutate(alt=substr(seq,alt_start_pos-pos+1+clipdistance_left,alt_start_pos-pos+1+clipdistance_left))
# snps=snps%>%filter(!alt%in%"N")
# snps=snps%>%filter(!ref%in%"") #filters out mutants outside the kinase domain

snps_sum=snps%>%group_by(alt_start_pos,ref,alt)%>%dplyr::summarize(ct=n())

# good=snps%>%filter(alt_start_pos%in%130873027)
# bad=snps%>%filter(alt_start_pos%in%130872175)
# 
# good_sum=snps_sum%>%filter(alt_start_pos%in%130873027)
# bad_sum=snps_sum%>%filter(alt_start_pos%in%130872175)
# sum(snps_sum$ct)
##########################MNVs########################################
#######Defining neighbor distance########
###For 2 nucleotide substitutions, 96% start at the start of the codon. The possibilites are for the substitutions to be side by side or be separated by a nucleotide. e.g. AAA could mutate to TTA or TAT. I need to know whether a TTA type substitution is happening or a TAT type substitution. Therefore I am defining a neighbordistance term
mnvs=alldata%>%mutate(n_nuc=str_count(mdz,"A|T|C|G"))%>%filter(n_nuc>=2)
mnvs=mnvs%>%
  mutate(neighbordistance=case_when(
    n_nuc%in%2&&head(strsplit(mdz,"A|G|C|T")[[1]][-1],-1)%in%0~0,
    n_nuc%in%2&&head(strsplit(mdz,"A|G|C|T")[[1]][-1],-1)%in%1~1,
    n_nuc%in%3&&sum(as.numeric(head(strsplit(mdz,"A|G|C|T")[[1]][-1],-1)))%in%0~0,
    TRUE~NaN))
# sum(as.numeric(head(strsplit("3A0C0T99","A|C|G|T")[[1]][-1],-1)))

# a=mnvs%>%filter(n_nuc<=3)
# mnvs$minuslast="NA"
# mnvs=mnvs%>%rowwise()%>%mutate(minuslast=head(strsplit(mdz,"A|G|C|T"),-1))
#######Filtering MNVs for side-by-side MNVs######
#Has to be within hamming distance of 2,
#Basically looking for a 0 or 1 with no neighboring numbers
# 30A0C0C94
# 38C0A3
# strsplit("30A0C0C94","A|G|C|T")
# head(strsplit("38C0A3","A|G|C|T")[[1]][-1],-1)
# a=lapply()
# a=mnvs%>%rowwise()%>%filter(head(strsplit(mdz,"A|G|C|T")[[1]][-1],-1)%in%"0")
list=mnvs$mdz
# i=1
mnv_status_compiled=rep("NA",length(list))
for(i in 1:length(list)){
  # i=1
  #To be considered a true variant, an mnv must meet two criteria: 1) have a 0 or 1 in the mdz field (hamming distance of <2), 2) not have >1 in the mdz field. This takes out potentially epistatic mutants, e.g. T315I and T243V seen on the same read. So this variant caller needs to be updated to not take out these automatically, but we can worry about that later. I only found 1 read with a 0 AND a 27 in the MDZ field for our D0 WT scenario.
  #Firstbasically searching if there's a 0 or a 1 in the MDZ field of the mnv
  #########Test for Criteria 1###############
  mnv_status_i=!grepl("2|3|4|5|6|7|8|9|11",head(strsplit(list[i],"A|G|C|T")[[1]][-1],-1))
  
  if(sum(as.numeric(mnv_status_i))>=1){
    mnv_status_compiled[i]=TRUE
    # mnv_status_compiled[i]=TRUE
  } else {
    mnv_status_compiled[i]=FALSE
  }
  #########Test for Criteria 2###############
  #Basically stating that if any of the MDZ fields are >=2, consider that mnv as not a true MNV. There's obviously room for improvement here because sometimes with mnvs you can have two separate mutations on the same read. Case in point: "3A1C27T99". But we'll ignore these for now.
  if(sum(
    as.numeric(
      as.numeric(
        head(
          strsplit(list[i],"A|G|C|T")[[1]][-1],-1))>=2))>0){
    mnv_status_compiled[i]=FALSE
  }
}
mnvs$mnv_status=mnv_status_compiled
# a=mnvs%>%filter(n_nuc<=3,soft_clipped%in%)
# sum(as.numeric(alldata$soft_clipped==T))

# class(mnvs$mnv_status)
#Regexp for 
# sum(as.numeric(mnvs$mnv_status))
# sum(mnvs$mnv_status%in%TRUE)

    

#### For my sscs replicates for novogene lane 4 il3 indep 1, I observed 3301 variant reads with >2 varaints out of which 1790 reads had variants that were side-by-side mnvs (hamming distance of 0 or 1)
#### For my dcs replicates, I observed 3301 variant reads with >2 varaints out of which 1790 reads had variants that were side-by-side mnvs (hamming distance of 0 or 1)
#We know that this library enriches for mnvs with hamming distance of <2 (true positive). The hypothesis is that if I were sequencing at a threshold below the error rate for sscs, then there would be a lot of reads in which the real mutant was masked by multiple nucleotide variants (hamming distance >2). However, if we were good on the sscs error rate, the type of sequencing would not predict whether a read with two variants had 
#Testing to see if the sscs or dcs predicts the hamming distance.
# fisher.test(rbind(c(1790,1511),c(596,470)))
# a=mnvs[mnvs$n_nuc<=3,]
# a=mnvs[mnvs$n_nuc==2,]
# a=mnvs[mnvs$mnv_status%in%F,]
# (strsplit(a$mdz,"A|G|C|T")[[1]][1])

# (strsplit(a$mdz,"A|G|C|T")[[1]][a$n_nuc[1]+1])
###Calculating which reads had one mutant at the end of the read. 10% of mnvs had mutant at end###
mnvs=mnvs%>%
  rowwise()%>%
  mutate(mut_extr=case_when(as.numeric(strsplit(mdz,"A|G|C|T")[[1]][1])%in%c(0,1)~T,
                          as.numeric(strsplit(mdz,"A|C|G|T")[[1]][n_nuc[1]+1])%in%c(0,1)~T,
                                          T~F))

mnvs=mnvs%>%filter(mut_extr%in%F,n_nuc<=4,soft_clipped%in%F,mnv_status%in%T)
  ###The following thoughts on L298L are outdated because I'm aligning directly to the ABL CDS from our plasmid and we don't see L298L anymore
  ###Calculating which reads had L298L in the read###
  #L298L occurs 20 residues into exon 5. What I realized is that a lot of mnvs for L298L had two wrong calls: one wrong call because the split read started in exon 4 and the variant caller thought there were mismatches in exon 5 when in fact it was looking at exon 4. Need to definitely take these into account.
  
  ###For mnvs with L298L or second mutant at the end of read, count the SNP only.###
  ####The majority of MNVs that we see are "bad" because the mutants don't occur right next to each other. For mnvs that have mutants that are far apart, there could be different things that are going on: 1) there are actually 2 mutants that are far apart (10% reads in saturation mutagenesis libraries), 2) one of the mutants is erroneous, would expect this for mutants called near the end of the read so will filter those out. 3) both mutants are technically mutants but only one of those is a true mutant. For our case, L298L was a true synonymous mutant present in our library hence every human ABL1 cDNA read near 298 should read this mutant. So I will figure out a way to NOT filter those out.###


#Determining the mnv start and end position on the genome
#For end position, if it's a 2 nuclteotide mnv that looks like a 3 nucleoitde mnv, add +1
mnvs=mnvs%>%
  rowwise()%>%
  mutate(alt_start_pos=pos+as.numeric(strsplit(mdz,"A|G|C|T")[[1]][1]),
         alt_end_pos=case_when(n_nuc%in%2&&neighbordistance%in%1~alt_start_pos+n_nuc+1,
                               T~alt_start_pos+n_nuc))



#Figuring out if mnv spans two codons
#Nearest real codon of an mnv is the one it starts right after. E.g. if we see mnv starting at position 100, it's nearest neighbor would be codon 99-102
#If it is a 3 nucleotide variant, it must start at the same start position as the start codon
#If it is a 2 nucleotide variant, its distance from the real codon can be 0 or 1 


mnvs=mnvs%>%
  rowwise()%>%
  mutate(in_frame_mnv=
           case_when(((alt_start_pos-645)%in%abl_genomic_coordinates$start)||((alt_end_pos-1-645)%in%abl_genomic_coordinates$end)~TRUE,
                     T~FALSE))
#^^Basically saying that an in-frame mnv has to start at the start of the codon or stop at the stop of the codon. An in-frame mnv has to either start or stop in the codon. e.g. 2 nucleotide substitution in AAA can be TAA or ATT or TAT. 

#Turns out most of these mnvs start at the start of a codon! Thats great, means they're real mnvs
###Turns out the majority of 2 nucleotide substitutions (96%) start at the first nucleotide in the codon. That's interesting. 
# a=mnvs%>%filter(n_nuc==2&&in_frame_mnv==FALSE)
mnvs=mnvs%>%filter(in_frame_mnv%in%TRUE)
# sort(unique(mnvs$alt_start_pos))



#Looks like T315V comprises most of the unique triple nucleotide mnvs. 15 unique Mnvs in this read so far #This was in the iL3 indep case
# a=mnvs%>%filter(alt_start_pos==130862940)%>%mutate(codon=substr(seq,alt_start_pos-pos+1,alt_start_pos-pos+3))
# sort(unique(a$codon))

mnvs=mnvs%>%mutate(ref=abl1_search(alt_start_pos-645,alt_end_pos-645))

mnvs=mnvs%>%
  rowwise()%>%
  mutate(alt=case_when(neighbordistance%in%0~substr(seq,alt_start_pos-pos+1+clipdistance_left,alt_start_pos-pos+2+clipdistance_left),
    T~substr(seq,alt_start_pos-pos+1+clipdistance_left,alt_start_pos-pos+3+clipdistance_left)))


#Filtering out ALT codons that contain Ns
#Do same for snps when you're there
# mnvs=mnvs[!grepl("N",mnvs$alt),]
#Not needed anymore becuase I filter out Ns in the filtering steps at the start of the code
###
# mnvs$id=paste(mnvs$alt_start_pos,mnvs$alt,sep="")
# mnvs$id=paste(mnvs$alt_start_pos,mnvs$ref,sep="")

mnv_sum=mnvs%>%group_by(alt_start_pos,alt_end_pos,ref,alt)%>%dplyr::summarize(ct=n())
# sum(mnv_sum$ct)

##########Annotating SNPS###############
# a=snps_sum[c(1:50),]
# a=vep_fromdf(a)

snps_sum=cds_to_hg38(snps_sum)
###Removing L298L because VEP can't deal with seeing an "ALT" that shows up as REF in hg38.
snps_sum=snps_sum%>%filter(!c(alt_start_hg38%in%130872200&alt=="G"), #L298L
                           !c(alt_start_hg38%in%130872215&alt=="T"), #Splice inconsistency ex4-5
                           !c(alt_start_hg38%in%130873038&alt=="G")) #Splice inconsistency ex5-6
# 130873038
# a=snps_sum%>%filter(alt_start_hg38%in%130872215)

snps_sum_ann=vep_fromdf(snps_sum)
snps_sum_ann$type="snp"
# snps_sum_ann=snps_ann
# a=snps_ann%>%filter(consequence_terms%in%"missense_variant")


snps_ann=merge(snps,snps_sum_ann,by=c("alt_start_pos","alt_end_pos","ref","alt"))

##########Annotating MNVs###############
mnv_sum=cds_to_hg38(mnv_sum)

mnv_sum_ann=vep_fromdf(mnv_sum)
mnv_sum_ann$type="mnv"
mnvs_ann=merge(mnvs,mnv_sum_ann,by=c("alt_start_pos","alt_end_pos","ref","alt"))
# a=vep_fromdf(a)


#####Merging MNVs and SNPS#####

snps_sum_ann$alt_end_pos=snps_sum_ann$alt_start_pos+1
snps_sum_ann_reformatted=snps_sum_ann%>%dplyr::select(type,
                                          alt_start_pos,
                                          alt_end_pos,
                                          ref,
                                          alt,
                                          ct,
                                          protein_start,
                                          protein_end,
                                          amino_acids,
                                          codons,
                                          impact,
                                          polyphen_prediction,
                                          consequence_terms)
# snps_sum_ann$protein_start

mnv_sum_ann_reformatted=mnv_sum_ann%>%dplyr::select(type,
                                          alt_start_pos,
                                          alt_end_pos,
                                          ref,
                                          alt,
                                          ct,
                                          protein_start,
                                          protein_end,
                                          amino_acids,
                                          codons,
                                          impact,
                                          polyphen_prediction,
                                          consequence_terms)

calls_sum_merged=rbind(snps_sum_ann_reformatted,mnv_sum_ann_reformatted)
# colnames(snps_ann)
# colnames(mnvs_ann)

# write.csv(calls_sum_merged,gsub(files[filecurr],pattern = ".tsv",replacement = "_calls.csv"))
calls_missense=calls_sum_merged%>%filter(consequence_terms%in%"missense_variant")
}
# calls_duplex=calls_sum_merged
# a=snps_ann%>%filter(protein_start%in%479)
# snps_ann_reformatted=snps_ann_reformatted%>%dplyr::select(type,
#                                           alt_start_pos,
#                                           alt_end_pos,
#                                           ref,
#                                           alt,
#                                           ct,
#                                           protein_start,
#                                           protein_end,
#                                           amino_acids,
#                                           codons,
#                                           impact,
#                                           polyphen_prediction,
#                                           consequence_terms)
```

```{r}

human_softclipped=snps_ann%>%filter(protein_start%in%c(250,253,252),soft_clipped%in%T)
mouse_softclipped=snps_ann%>%filter(protein_start%in%c(379,394,479),soft_clipped%in%T)
human_softclipped_unexpected=snps_ann%>%filter(protein_start%in%c(256,288,292,314,319,324,331,339))

sum(as.numeric(human_softclipped$mlen>=70))
ggplot(a,aes(y=slen))+geom_boxplot()
mean(human_softclipped$clipdistance_total)
mean(mouse_softclipped$clipdistance_total)
mean(mouse_softclipped$clipdistance_left)

a=snps%>%filter(c(alt_start_pos%in%"942"&ref%in%"G"))
ggplot(input_df,aes(x=protein_start,y=ct))+geom_col()
ggplot(calls_duplex,aes(x=protein_start,y=ct))+geom_col()

```

