---
title: "dosing_normalization"
author: "Haider Inam"
date: "6/1/2020"
output: html_document
---
This is a strategy that uses the observed GFP growth rates to estimate the approximate experimental dose and then normalizes all mutants to behave at that theoretical dose given an arbitrary hill coefficient in a dose response curve.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,include=F}
# rm(list=ls())
library(knitr)
library(tictoc)
library(workflowr)
library(VennDiagram)
library(dplyr)
library(foreach)
library(doParallel)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library(devtools)
library(ggsignif)
library(plotly)
library(BiocManager)
library(drc)
library("lmtest")
library("ggplot2")
library("MASS")
library("fitdistrplus")
library("lme4")
library("boot")
library("dplyr")
library("plotly")
library(drc)
library(devtools)
library(deSolve)
library(RColorBrewer)
library(reshape2)
######################Cleanup for GGPlot2#########################################
cleanup=theme_bw() +
  theme(plot.title = element_text(hjust=.5),
        panel.grid.major = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(color = "black"),
        axis.text = element_text(face="bold",color="black",size="11"),
        text=element_text(size=11,face="bold"),
        axis.title=element_text(face="bold",size="11"))


net_gr_wodrug=0.055
# ic50data_long=read.csv("../output/ic50data_all_conc.csv",header = T,stringsAsFactors = F,row.names=1)
ic50data_long=read.csv("output/ic50data_all_conc.csv",header = T,stringsAsFactors = F,row.names=1)
ic50data_long$netgr_pred=net_gr_wodrug-ic50data_long$drug_effect


# twinstrand_simple_melt_merge=read.csv("../output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)
twinstrand_simple_melt_merge=read.csv("output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)
```
  
### Part 1: Analysis of typical dosing errors.  
#### Theoretically, how much can an error in dosing change the replicate to replicate heterogeneity observed in an experiment?

```{r}

#Looking at data that is off.
#First, I will look at data from IC50 predictions and make a correlation plot of netgr of mutants expected at 625nM vs 1.25uM.
#Next, I will look at whether any of our replicates seemed off
    a=ic50data_long%>%filter(conc%in%c(.6,1.2))
    a_cast=dcast(a,mutant~conc)
# library(reshape2)
ic50data_cast=dcast(ic50data_long,mutant~conc)
ic50data_cast6=ic50data_cast%>%dplyr::select(mutant,`0.9`)
a=ic50data_long%>%filter(conc==0.9)
# ic50data_long$`0.6`=ic50data_long%>%filter(conc==0.6)%>%dplyr::select(netgr_pred)
a=merge(ic50data_cast6,ic50data_long,by="mutant")
# ic50data_long$`0.6`=ic50data_cast$`0.6`
# ic50data_long=ic50data_long%>%mutate(`0.6`=ic50data_cast$`0.6`)
a=a%>%filter(conc%in%c(.4,.6,.8,1,1.2,1.4))
getPalette = colorRampPalette(brewer.pal(6, "Spectral"))
plotly=ggplot(a,aes(x=`0.9`,y=netgr_pred))+
  geom_abline()+
  geom_point(color="black",shape=21,size=3,aes(fill=factor(conc)))+
  scale_fill_manual(values = getPalette(length(unique(a$conc))))+
  cleanup
ggplotly(plotly)

########Making figure with predicted growth over various concentrations
ic50data_cast=dcast(ic50data_long,mutant~conc)
ic50data_cast6=ic50data_cast%>%dplyr::select(mutant,`0.8`)
a=merge(ic50data_cast6,ic50data_long,by="mutant")
a=a%>%filter(conc%in%c(.4,.8,1.2))

####Sorting mutants from more to less resistant
ic50data_long_625=a%>%filter(conc==.8)
a$mutant=factor(a$mutant,levels = as.character(ic50data_long_625$mutant[order((ic50data_long_625$y),decreasing = T)]))
###
getPalette = colorRampPalette(brewer.pal(3, "Spectral"))
ggplot(a,aes(x=`0.8`,y=netgr_pred))+
  geom_abline()+
  geom_point(color="black",shape=21,size=4,aes(fill=factor(conc)))+
  scale_x_continuous(limits=c(-.01,.06),name="Theoretical Growth rate")+
  scale_y_continuous(limits=c(-.01,.06),name="Theoretical Growth rate with 50% error in dose")+
  scale_fill_manual(values = getPalette(length(unique(a$conc))))+
  cleanup+
  theme(legend.position = "none")
# ggsave("dosing_error_r1r2.pdf",width=3,height=3,units="in",useDingbats=F)

ggplot(a,aes(x=mutant,y=netgr_pred,color=factor(conc)))+
  geom_abline()+
  geom_point(color="black",shape=21,size=4,aes(fill=factor(conc)))+
  # scale_x_continuous(limits=c(1.33/72,1.405/72),name="Theoretical Growth rate \nat intended concentration")+
  scale_y_continuous(limits=c(-.01,.06),name="Theoretical Growth rate")+
  scale_fill_manual(values = getPalette(length(unique(a$conc))))+
  cleanup+
  theme(legend.position = "none",
        axis.title.x = element_blank(),
        axis.text.x=element_text(angle=90,hjust=.5,vjust=.5))

# ggsave("dosing_error_r1mutant.pdf",width=5,height=3,units="in",useDingbats=F)
```
  
### Part 2: Hill Coefficient Analysis.  
#### What Hill Coefficient to Use When inferring growth rates based on apparent dose?  
We'll need to assume a hill coefficient if we want to normalize the dose response of these mutants. Below, you will see that the typical hill coefficient in our dataset is centered around 2-3. Therefore, it is safe to assume that the hill coefficient for all the mutants is around the one forthe standard (E255K)
```{r}
ic50data=read.csv("data/heatmap_concat_data.csv",header = T,stringsAsFactors = F)
# ic50data=read.csv("../data/heatmap_concat_data.csv",header = T,stringsAsFactors = F)
ic50data=ic50data[c(1:10),]
ic50data_long=melt(ic50data,id.vars = "conc",variable.name = "species",value.name = "y")
#Removing useless mutants (for example keeping only maxipreps and removing low growth rate mutants)
ic50data_long=ic50data_long%>%filter(species%in%c("Wt","V299L_H","E355A","D276G_maxi","H396R","F317L","F359I","E459K","G250E","F359C","F359V","M351T","L248V","E355G_maxi","Q252H_maxi","Y253F","F486S_maxi","H396P_maxi","E255K","Y253H","T315I","E255V"))
#Making standardized names
ic50data_long$mutant=ic50data_long$species
ic50data_long=ic50data_long%>%
  # filter(conc=="0.625")%>%
  # filter(conc=="1.25")%>%
  mutate(mutant=case_when(species=="F486S_maxi"~"F486S",
                          species=="H396P_maxi"~"H396P",
                          species=="Q252H_maxi"~"Q252H",
                          species=="E355G_maxi"~"E355G",
                          species=="D276G_maxi"~"D276G",
                          species=="V299L_H" ~ "V299L",
                          species==mutant ~as.character(mutant)))

# ic50data_long_625$species[order((ic50data_long_625$y),decreasing = T)]

#In the next step, I'm ordering mutants by decreasing resposne to the 625nM dose. Then I use this to change the levels of the species factor from more to less resistant. This helps with ggplot because now I can color the mutants with decreasing resistance
ic50data_long_625=ic50data_long%>%filter(conc==.625)
ic50data_long$species=factor(ic50data_long$species,levels = as.character(ic50data_long_625$species[order((ic50data_long_625$y),decreasing = T)]))
ic50data_long$mutant=factor(ic50data_long$mutant,levels = as.character(ic50data_long_625$mutant[order((ic50data_long_625$y),decreasing = T)]))

########Four parameter logistic########
#Reference: https://journals.plos.org/plosone/article/file?type=supplementary&id=info:doi/10.1371/journal.pone.0146021.s001
#In short: For each dose in each species, get the response
# rm(list=ls())
ic50data_long_model=data.frame()
# hill_coefficients=data.frame()
hill_coefficients_cum=data.frame()
ic50data_long$species=ic50data_long$mutant
for (species_curr in sort(unique(ic50data_long$species))){
  ic50data_species_specific=ic50data_long%>%filter(species==species_curr)
  x=ic50data_species_specific$conc
  y=ic50data_species_specific$y
  #Next: Appproximating Response from dose (inverse of the prediction)
  ic50.ll4=drm(y~conc,data=ic50data_long%>%filter(species==species_curr),fct=LL.3(fixed=c(NA,1,NA)))
    b=coef(ic50.ll4)[1]
    c=0
    d=1
    e=coef(ic50.ll4)[2]
  ###Getting predictions
  ic50data_species_specific=ic50data_species_specific%>%group_by(conc)%>%mutate(y_model=c+((d-c)/(1+exp(b*(log(conc)-log(e))))))
  ic50data_species_specific=data.frame(ic50data_species_specific) #idk why I have to end up doing this
  ic50data_long_model=rbind(ic50data_long_model,ic50data_species_specific)
  hill_coefficients_curr=data.frame(cbind(species_curr,b,e))
  # hill_coefficients$species=species_curr
  # hill_coefficients$hill=b
  hill_coefficients_cum=rbind(hill_coefficients_cum,hill_coefficients_curr)
}
ic50data_long=ic50data_long_model

#In the next step, I'm ordering mutants by decreasing resposne to the 625nM dose. Then I use this to change the levels of the species factor from more to less resistant. This helps with ggplot because now I can color the mutants with decreasing resistance
ic50data_long_625=ic50data_long%>%filter(conc==.625)
ic50data_long$species=factor(ic50data_long$species,levels = as.character(ic50data_long_625$species[order((ic50data_long_625$y_model),decreasing = T)]))

#Adding drug effect
##########Changed this on 2/20. Using y from 4 parameter logistic rather than raw values
ic50data_long=ic50data_long%>%
  filter(!species=="Wt")%>%
  mutate(drug_effect=-log(y_model)/72)

#Adding Net growth rate
ic50data_long$netgr_pred=.05-ic50data_long$drug_effect

hill_coefficients_cum$b=as.numeric(hill_coefficients_cum$b)
ggplot(hill_coefficients_cum,aes(b))+geom_histogram()
ggplot(hill_coefficients_cum,aes(x=species_curr,y=b))+geom_point()
#Maybe we can assume a hill of 2?



###Preparing spreadsheet of hill coefficients for MCMC. 06072020
a=hill_coefficients_cum%>%dplyr::select(mutant=species_curr,hill_coef=b,ic50=e)
rownames(a)=NULL
# write.csv(a,"bcrabl_hill_ic50s.csv")
```
### Part 3: Correcting microvariations.    
#### Dosing normalization function that corrects for microvariations.  
####  Now that we know that an off dose can have massive implications on the replicate to replicate agreement, we are going to correct it.  
  
#### Method 1: Use the apparent dose of the standard (E255K in this case) to normalize the growth rates of the other mutants to the same apparent dose  
Using the dosing normalization function
```{r}

####First, we choose our model experiment and calculate the apparent dose at that model experiment using the net growth rate of the standard.
#Apparent dose of E255K (standard) for M3 (model experiment)
# ((1-exp((net_gr_wodrug-0.033481)*time))*-(ic50_standard^hill_standard))^(1/hill_standard)
#We will use this as the apparent dose for our model experiment. Will normalize all other experiments to this dose.
# twinstrand_simple_melt_merge=read.csv("../output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)
twinstrand_simple_melt_merge=read.csv("output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)

# source("../code/microvariation.normalizer.R")
source("code/microvariation.normalizer.R")

#Focusing on the non-ENU experiments
twinstrand_simple_melt_merge=twinstrand_simple_melt_merge%>%filter(!experiment%in%c("Enu_3","Enu_4"))
net_gr_wodrug=0.055
time=72
hill_standard=2.83 #E255K Hill
ic50_standard=1.205 #E255K IC50
standard_name="E255K"
dose_model=1.9147 #M3 dose

netgr_corrected_compiled=data.frame()
dose_apparent_compiled=data.frame()
for(experiment_current in unique(twinstrand_simple_melt_merge$experiment)){
  netgr_raw=twinstrand_simple_melt_merge%>%
    filter(experiment==experiment_current,duration=="d3d6")%>%
    dplyr::select(experiment,mutant,netgr_obs)
  
  ###For one experiment###
  netgr_corrected_experiment=microvariation.normalizer(netgr_raw,
                                     net_gr_wodrug,
                                     hill_standard,
                                     ic50_standard,
                                     dose_model,
                                     time,
                                     standard_name)[[1]]
  #Dose apparent
  dose_apparent_experiment=microvariation.normalizer(netgr_raw,
                                     net_gr_wodrug,
                                     hill_standard,
                                     ic50_standard,
                                     dose_model,
                                     time,
                                     standard_name)[[2]]

  netgr_corrected_compiled=rbind(netgr_corrected_experiment,netgr_corrected_compiled) #Of course faster way would be pre-allocating for efficiency
  dose_apparent_compiled=rbind(c(experiment_current,dose_apparent_experiment),dose_apparent_compiled)
}
#adding m3's growth rates as the model
netgr_corrected_compiled=merge(netgr_corrected_compiled,netgr_corrected_compiled%>%filter(experiment%in%"M3")%>%dplyr::select(mutant,netgr_model_m3=netgr_obs),by="mutant")
netgr_corrected_compiled=merge(netgr_corrected_compiled,netgr_corrected_compiled%>%filter(experiment%in%"M4")%>%dplyr::select(mutant,netgr_model_m4=netgr_obs),by="mutant")
# #Adding all experiments
# for experiment_curr%in%sort(unique(netgr_corrected_compiled$experiment)){
#   
# }

ggplot(netgr_corrected_compiled,aes(x=netgr_model_m3,y=netgr_obs,color=experiment))+geom_point()+geom_abline()
ggplot(netgr_corrected_compiled,aes(x=netgr_model_m3,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()


###Looking at whether we can correct by mean growth rate for E255K
# netgr_model=netgr_corrected_compiled%>%group_by(mutant)%>%summarize(netgr_model=mean(netgr_obs,na.rm=T),netgr_model_corrected=mean(netgr_obs_corrected,na.rm=T))
# ggplot(netgr_model,aes(x=netgr_model,y=netgr_model_corrected))+geom_point()+geom_abline()
# a=merge(netgr_corrected_compiled,netgr_model,by="mutant")
# ggplot(a,aes(x=netgr_model,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()
# ggplot(a,aes(x=netgr_model_corrected,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()

#Problem right now: For stuff that has a growth rate higher than netgr_obs, how do you correct it? Because those things apparently have an infinite IC50    
####Calculating mean squared error
a=netgr_corrected_compiled%>%filter(!experiment%in%"M3")%>%mutate(sq_error=(netgr_model_m3-netgr_obs_corrected)^2)
mean(a$sq_error,na.rm=T)
b=netgr_corrected_compiled%>%filter(!experiment%in%"M3")%>%mutate(sq_error=(netgr_model_m3-netgr_obs)^2)
mean(b$sq_error,na.rm=T)
mean(b$sq_error,na.rm=T)/mean(a$sq_error,na.rm=T)


####Making publication ready plots
netgr_corrected_compiled_forplot=melt(netgr_corrected_compiled,id.vars = c("mutant","experiment","netgr_model_m3","netgr_model_m4"),measure.vars = c("netgr_obs","netgr_obs_corrected"),variable.name = "correction_status",value.name = "netgr_obs")
# write.csv(netgr_corrected_compiled_forplot,"twinstrand_microvariations_normalized.csv",row.names = F)

netgr_corrected_compiled_forplot=netgr_corrected_compiled_forplot%>%
  filter(!experiment%in%"M3")%>%
  mutate(correction_status_name=
           case_when(correction_status=="netgr_obs"~"Raw",
                     correction_status=="netgr_obs_corrected"~"Corrected"))
netgr_corrected_compiled_forplot$correction_status_name=factor(netgr_corrected_compiled_forplot$correction_status_name,levels=c("Raw","Corrected"))

ggplot(netgr_corrected_compiled_forplot,aes(y=netgr_obs,x=netgr_model_m3))+
  geom_abline()+
  geom_point()+
  facet_wrap(~correction_status_name)+
  cleanup+
  scale_y_continuous(name="Growth rate of \n model replicate",limits=c(0,0.06))+
  scale_x_continuous(name="Growth rate of other replicates",limits=c(0,0.06))+
  theme(axis.text.x = element_text(size=11),
        axis.text.y = element_text(size=11),
        axis.title = element_text(size=11))

# ggsave("dosing_normalization_simple_e255k.pdf",width=5,height=3,units="in",useDingbats=F)

ggplot(netgr_corrected_compiled_forplot,aes(x=netgr_model_m3,y=netgr_obs,color=correction_status_name))+geom_abline()+geom_point()+facet_wrap(~experiment)+cleanup


ggplot(netgr_corrected_compiled_forplot%>%filter(experiment%in%c("M3","M5")),aes(x=netgr_model_m3,y=netgr_obs,color=correction_status_name))+geom_abline()+geom_point(color="black",shape=21,size=2,aes(fill=correction_status_name))+cleanup+scale_x_continuous(name="Replicate 1",limits=c(0,.06))+scale_y_continuous(name="Replicate 2",limits=c(0,.06))+scale_fill_manual(values = c("black","gray90"))+theme(legend.position = "none",axis.text = element_blank(),axis.ticks = element_blank())

# ggsave("r1r2_1in3000.pdf",width = 2,height=2,units="in",useDingbats=F)

ggplot(netgr_corrected_compiled_forplot%>%filter(experiment%in%c("M3","M7")),aes(x=netgr_model_m3,y=netgr_obs,color=correction_status_name))+geom_abline()+geom_point(color="black",shape=21,size=2,aes(fill=correction_status_name))+cleanup+scale_x_continuous(name="Replicate 1",limits=c(0,.06))+scale_y_continuous(name="Replicate 3",limits=c(0,.06))+scale_fill_manual(values = c("black","gray90"))+theme(legend.position = "none",axis.text = element_blank(),axis.ticks = element_blank())

# ggsave("r1r3_1in3000.pdf",width = 2,height=2,units="in",useDingbats=F)

ggplot(netgr_corrected_compiled_forplot%>%filter(experiment%in%c("M3","M6")),aes(x=netgr_model_m3,y=netgr_obs,color=correction_status_name))+geom_abline()+geom_point(color="black",shape=21,size=2,aes(fill=correction_status_name))+cleanup+scale_x_continuous(name="Replicate 1",limits=c(0,.06))+scale_y_continuous(name="Replicate 2",limits=c(0,.06))+scale_fill_manual(values = c("black","gray90"))+theme(legend.position = "none",axis.text = element_blank(),axis.ticks = element_blank())

# ggsave("r1r2_1in5000.pdf",width = 2,height=2,units="in",useDingbats=F)


# netgr_corrected_compiled_forplot=netgr_corrected_compiled_forplot%>%dplyr::select(mutant,experiment,correction_status,netgr_obs)

```
  
#### Method 2: Using MCMC, we decided on the apparent dose of mutants based on the net growth rates of 4 standards (we used T315I, L248V, Y253F, and F359V). With the apparent doses for all the replicates, we normalize their growth rates to the same apparent dose  

```{r}
###Outputs of MCMC code
mcmc_apparent_doses=data.frame(rbind(c("M3",0.9159),c("M4",1.4261),c("M5",1.4541),c("M6",1.35),c("M7",1.345)))
mcmc_apparent_doses=mcmc_apparent_doses%>%dplyr::select(experiment=X1,dose_app=X2)

# source("../code/microvariation.normalizer.R")
source("code/microvariation.normalizer.R")

#Focusing on the non-ENU experiments
twinstrand_simple_melt_merge=twinstrand_simple_melt_merge%>%filter(!experiment%in%c("Enu_3","Enu_4"))
net_gr_wodrug=0.055
time=72
hill_standard=2.83 #E255K Hill
ic50_standard=1.205 #E255K IC50
standard_name="E255K"
dose_model=0.9159 #M3 dose

netgr_corrected_compiled=data.frame()
dose_apparent_compiled=data.frame()
for(experiment_current in unique(twinstrand_simple_melt_merge$experiment)){
  netgr_raw=twinstrand_simple_melt_merge%>%
    filter(experiment==experiment_current,duration=="d3d6")%>%
    dplyr::select(experiment,mutant,netgr_obs)
  
  ###For one experiment###
  netgr_corrected_experiment=microvariation.normalizer(netgr_raw,
                                     net_gr_wodrug,
                                     hill_standard,
                                     ic50_standard,
                                     dose_model,
                                     time,
                                     standard_name,
                                     mcmc=TRUE,
                                     dose_app_mcmc=as.numeric(mcmc_apparent_doses%>%filter(experiment%in%experiment_current)%>%dplyr::select(dose_app)))[[1]]
  #Dose apparent
  dose_apparent_experiment=microvariation.normalizer(netgr_raw,
                                     net_gr_wodrug,
                                     hill_standard,
                                     ic50_standard,
                                     dose_model,
                                     time,
                                     standard_name,
                                     mcmc=TRUE,
                                     dose_app_mcmc=as.numeric(mcmc_apparent_doses%>%filter(experiment%in%experiment_current)%>%dplyr::select(dose_app)))[[2]]

  netgr_corrected_compiled=rbind(netgr_corrected_experiment,netgr_corrected_compiled) #Of course faster way would be pre-allocating for efficiency
  dose_apparent_compiled=rbind(c(experiment_current,dose_apparent_experiment),dose_apparent_compiled)
}
#adding m3's growth rates as the model
netgr_corrected_compiled=merge(netgr_corrected_compiled,netgr_corrected_compiled%>%filter(experiment%in%"M3")%>%dplyr::select(mutant,netgr_model_m3=netgr_obs),by="mutant")

plotly=ggplot(netgr_corrected_compiled,aes(x=netgr_model_m3,y=netgr_obs,color=experiment))+geom_point()+geom_abline()
ggplotly(plotly)
plotly=ggplot(netgr_corrected_compiled,aes(x=netgr_model_m3,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()
ggplotly(plotly)



####Calculating mean squared error
a=netgr_corrected_compiled%>%filter(!experiment%in%"M3")%>%mutate(sq_error=(netgr_model_m3-netgr_obs_corrected)^2)
mean(a$sq_error,na.rm=T)
b=netgr_corrected_compiled%>%filter(!experiment%in%"M3")%>%mutate(sq_error=(netgr_model_m3-netgr_obs)^2)
mean(b$sq_error,na.rm=T)
mean(b$sq_error,na.rm=T)/mean(a$sq_error,na.rm=T)


####Making publication ready plots
netgr_corrected_compiled_forplot=melt(netgr_corrected_compiled,id.vars = c("mutant","experiment","netgr_model_m3"),measure.vars = c("netgr_obs","netgr_obs_corrected"),variable.name = "correction_status",value.name = "netgr_obs")
netgr_corrected_compiled_forplot=netgr_corrected_compiled_forplot%>%
  filter(!experiment%in%"M3")%>%
  mutate(correction_status_name=
           case_when(correction_status=="netgr_obs"~"Raw",
                     correction_status=="netgr_obs_corrected"~"Corrected"))
netgr_corrected_compiled_forplot$correction_status_name=factor(netgr_corrected_compiled_forplot$correction_status_name,levels=c("Raw","Corrected"))

ggplot(netgr_corrected_compiled_forplot,aes(y=netgr_obs,x=netgr_model_m3))+
  geom_abline()+
  geom_point()+
  facet_wrap(~correction_status_name)+
  cleanup+
  scale_y_continuous(name="Growth rate of \n model replicate",limits=c(0,0.06))+
  scale_x_continuous(name="Growth rate of other replicates",limits=c(0,0.06))+
  theme(axis.text.x = element_text(size=11),
        axis.text.y = element_text(size=11),
        axis.title = element_text(size=11))

# ggsave("dosing_normalization_simple_mcmc.pdf",width=5,height=3,units="in",useDingbats=F)

ggplot(netgr_corrected_compiled_forplot,aes(x=netgr_model_m3,y=netgr_obs,color=correction_status_name))+geom_abline()+geom_point()+facet_wrap(~experiment)+cleanup
```
###Part 4: Correcting ENU replicates
#### We will use Method 2 MCMC method: Use the apparent dose of the standard (E255K in this case) to normalize the growth rates of the other mutants to the same apparent dose  
```{r}
rm(list=ls())
cleanup=theme_bw() +
  theme(plot.title = element_text(hjust=.5),
        panel.grid.major = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(color = "black"),
        axis.text = element_text(face="bold",color="black",size="11"),
        text=element_text(size=11,face="bold"),
        axis.title=element_text(face="bold",size="11"))
conc_for_predictions=0.8
net_gr_wodrug=.055
# twinstrand_maf_merge=read.csv("../output/twinstrand_maf_merge.csv",header = T,stringsAsFactors = F)
twinstrand_maf_merge=read.csv("output/twinstrand_maf_merge.csv",header = T,stringsAsFactors = F)

# ic50data_long=read.csv("../output/ic50data_all_conc.csv",header = T,stringsAsFactors = F,row.names=1)
ic50data_long=read.csv("output/ic50data_all_conc.csv",header = T,stringsAsFactors = F,row.names=1)
################Remaking Twinstrand Simple Melt Merge################
twinstrand_simple=twinstrand_maf_merge%>%filter(!is.na(mutant),!is.na(experiment))
twinstrand_simple=twinstrand_simple%>%dplyr::select("mutant","experiment","Spike_in_freq","time_point","totalmutant")
###Inferring Enu_4 D0 total mutants to be the same as Enu_3 D0 totals
  twinstrand_simple_enu4d0=twinstrand_simple%>%filter(experiment=="Enu_4",time_point=="D0")%>%mutate(experiment="Enu_3")
  twinstrand_simple=rbind(twinstrand_simple,twinstrand_simple_enu4d0)
twinstrand_simple_cast=dcast(twinstrand_simple,mutant+experiment+Spike_in_freq~time_point,value.var="totalmutant")

twinstrand_simple_cast$d0d3=log(twinstrand_simple_cast$D3/twinstrand_simple_cast$D0)/72
twinstrand_simple_cast$d3d6=log(twinstrand_simple_cast$D6/twinstrand_simple_cast$D3)/72
twinstrand_simple_cast$d0d6=log(twinstrand_simple_cast$D6/twinstrand_simple_cast$D0)/144

# twinstrand_simple_cast2=twinstrand_simple_cast%>%group_by(mutant)%>%mutate(case_when(D0=experiment=="Enu_3"~D0[experiment=="Enu_4"]))
#Check if ln(final/initial)/time is the correct formula. Also notice how I'm using days not hours
twinstrand_simple_melt=melt(twinstrand_simple_cast[,-c(4:6)],id.vars=c("mutant","experiment","Spike_in_freq"),variable.name = "duration",value.name = "netgr_obs") #!!!!!!!!!!!value name should be drug effect. And drug effect should be drug_effect_obs i think. NO. I think this should be drug_effect_obs. Fixed 4/2/20
twinstrand_simple_melt$drug_effect_obs=net_gr_wodrug-twinstrand_simple_melt$netgr_obs

# twinstrand_simple_melt_merge=merge(twinstrand_simple_melt,ic50data_formerge,"mutant")
twinstrand_simple_melt_merge=merge(twinstrand_simple_melt,ic50data_long%>%filter(conc==conc_for_predictions),all.x = T)



# a=twinstrand_simple_melt%>%filter(experiment%in%"Enu_3")
# a=twinstrand_simple_cast%>%filter(experiment%in%"Enu_3")
# a=twinstrand_maf_merge%>%filter(experiment%in%"Enu_3",time_point=="D3")
#########################

####Plotting replicate 1 vs replicate 2 in two ways.
#1. Use only replicates in which you have sufficient coverage for mutants on D6
#2. Instead of using D3 and D6 counts. Use D0 and D3 counts. Since you didn't have counts for ENU for D3, assume that counts for Enu_3 at D0 would have looked the same as ENU_4 at D0.
#One interesting thing that I noticed is that D0-D3 growth rates for ENU3 and 4 were alike However D3 to D6 growth rates were higher for Enu3 than Enu4. Is it possible you measured Enu3 late? Yes, it does look like you measured Enu3 at 144 hours vs ENU 3 at 133 hours which might be causing the increased apparent growth rate of ENU3

enu_plots=twinstrand_simple_melt_merge%>%filter(experiment%in%c("Enu_4","Enu_3"),duration%in%"d3d6",!netgr_obs%in%NA)
#hardcoding adjustments to the growth rates
enu_plots$netgr_obs[enu_plots$experiment=="Enu_3"]=enu_plots$netgr_obs[enu_plots$experiment=="Enu_3"]

enu_cast=dcast(enu_plots,formula = mutant~experiment,value.var = "netgr_obs")

```

Using the dosing normalization function for ENU
Caveat: Now we're using L248V as a standard, and using d0d3 counts rather than d3d6 counts. Also assuming Enu_4 D0 counts were similar to Enu_3 D0 counts
```{r}
# # rm(list=ls())
# cleanup=theme_bw() +
#   theme(plot.title = element_text(hjust=.5),
#         panel.grid.major = element_blank(),
#         panel.grid.major.y = element_blank(),
#         panel.background = element_blank(),
#         axis.line = element_line(color = "black"),
#         axis.text = element_text(face="bold",color="black",size="11"),
#         text=element_text(size=11,face="bold"),
#         axis.title=element_text(face="bold",size="11"))
# twinstrand_simple_melt_merge=read.csv("../output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)
twinstrand_simple_melt_merge=read.csv("output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)
####First, we choose our model experiment and calculate the apparent dose at that model experiment using the net growth rate of the standard.
#Apparent dose of E255K (standard) for M3 (model experiment)
# ((1-exp((net_gr_wodrug-0.033481)*time))*-(ic50_standard^hill_standard))^(1/hill_standard)
#We will use this as the apparent dose for our model experiment. Will normalize all other experiments to this dose.

# source("../code/microvariation.normalizer.R")
source("code/microvariation.normalizer.R")

#Focusing on the ENU only experiments
twinstrand_simple_melt_merge=twinstrand_simple_melt_merge%>%filter(!experiment%in%c("M3","M4","M5","M6","M7"))
net_gr_wodrug=0.065
time=72
hill_standard=0.789 #E255K Hill
ic50_standard=2.325 #E255K IC50
standard_name="L248V"
dose_model=3.694476 #M3 dose

netgr_corrected_compiled=data.frame()
dose_apparent_compiled=data.frame()
# experiment_current="Enu_3"
for(experiment_current in unique(twinstrand_simple_melt_merge$experiment)){
  netgr_raw=twinstrand_simple_melt_merge%>%
    filter(experiment==experiment_current,duration=="d0d3")%>%
    dplyr::select(experiment,mutant,netgr_obs)
  # netgr_raw=twinstrand_simple_melt_merge%>%
  #   filter(experiment==experiment_current,duration=="d3d6")%>%
  #   dplyr::select(experiment,mutant,netgr_obs)
  
  
  
  
  ###For one experiment###
  netgr_corrected_experiment=microvariation.normalizer(netgr_raw,
                                     net_gr_wodrug,
                                     hill_standard,
                                     ic50_standard,
                                     dose_model,
                                     time,
                                     standard_name)[[1]]
  #Dose apparent
  dose_apparent_experiment=microvariation.normalizer(netgr_raw,
                                     net_gr_wodrug,
                                     hill_standard,
                                     ic50_standard,
                                     dose_model,
                                     time,
                                     standard_name)[[2]]

  netgr_corrected_compiled=rbind(netgr_corrected_experiment,netgr_corrected_compiled) #Of course faster way would be pre-allocating for efficiency
  dose_apparent_compiled=rbind(c(experiment_current,dose_apparent_experiment),dose_apparent_compiled)
}
#adding m3's growth rates as the model
netgr_corrected_compiled=merge(netgr_corrected_compiled,netgr_corrected_compiled%>%filter(experiment%in%"Enu_4")%>%dplyr::select(mutant,netgr_model_m3=netgr_obs),by="mutant")

ggplot(netgr_corrected_compiled,aes(x=netgr_model_m3,y=netgr_obs,color=experiment))+geom_point()+geom_abline()
ggplot(netgr_corrected_compiled,aes(x=netgr_model_m3,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()


###Looking at whether we can correct by mean growth rate for E255K
# netgr_model=netgr_corrected_compiled%>%group_by(mutant)%>%summarize(netgr_model=mean(netgr_obs,na.rm=T),netgr_model_corrected=mean(netgr_obs_corrected,na.rm=T))
# ggplot(netgr_model,aes(x=netgr_model,y=netgr_model_corrected))+geom_point()+geom_abline()
# a=merge(netgr_corrected_compiled,netgr_model,by="mutant")
# ggplot(a,aes(x=netgr_model,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()
# ggplot(a,aes(x=netgr_model_corrected,y=netgr_obs_corrected,color=experiment))+geom_point()+geom_abline()

#Problem right now: For stuff that has a growth rate higher than netgr_obs, how do you correct it? Because those things apparently have an infinite IC50    
####Calculating mean squared error
a=netgr_corrected_compiled%>%filter(!experiment%in%"Enu_4")%>%mutate(sq_error=(netgr_model_m3-netgr_obs_corrected)^2)
mean(a$sq_error,na.rm=T)
b=netgr_corrected_compiled%>%filter(!experiment%in%"Enu_4")%>%mutate(sq_error=(netgr_model_m3-netgr_obs)^2)
mean(b$sq_error,na.rm=T)
mean(b$sq_error,na.rm=T)/mean(a$sq_error,na.rm=T)


####Making publication ready plots
netgr_corrected_compiled_forplot=melt(netgr_corrected_compiled,id.vars = c("mutant","experiment","netgr_model_m3"),measure.vars = c("netgr_obs","netgr_obs_corrected"),variable.name = "correction_status",value.name = "netgr_obs")
netgr_corrected_compiled_forplot=netgr_corrected_compiled_forplot%>%
  filter(!experiment%in%"Enu_4")%>%
  mutate(correction_status_name=
           case_when(correction_status=="netgr_obs"~"Raw",
                     correction_status=="netgr_obs_corrected"~"Corrected"))
netgr_corrected_compiled_forplot$correction_status_name=factor(netgr_corrected_compiled_forplot$correction_status_name,levels=c("Raw","Corrected"))

ggplot(netgr_corrected_compiled_forplot,aes(y=netgr_obs,x=netgr_model_m3))+
  geom_abline()+
  geom_point()+
  facet_wrap(~correction_status_name)+
  cleanup+
  scale_y_continuous(name="Growth rate of \n model replicate",limits=c(0,0.068))+
  scale_x_continuous(name="Growth rate of other replicates",limits=c(0,0.068))+
  theme(axis.text.x = element_text(size=11),
        axis.text.y = element_text(size=11),
        axis.title = element_text(size=11))

# ggsave("dosing_normalization_simple_e255k.pdf",width=5,height=3,units="in",useDingbats=F)

ggplot(netgr_corrected_compiled_forplot,aes(x=netgr_model_m3,y=netgr_obs,color=correction_status_name))+geom_abline()+geom_point()+facet_wrap(~experiment)+cleanup
```
```{r}
# twinstrand_simple_melt_merge=read.csv("../output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)
twinstrand_simple_melt_merge=read.csv("output/twinstrand_simple_melt_merge.csv",header = T,stringsAsFactors = F,row.names=1)

a=twinstrand_simple_melt_merge%>%
    filter(experiment%in%c("Enu_4","Enu_3"))%>%
    dplyr::select(experiment,duration,mutant,netgr_obs)
a=a%>%filter(!(experiment%in%"Enu_3"&duration%in%c("d0d6","d0d3")))
```

To do: what if you used the actual hill coefficients of the mutants rather than E255K's hill coefficient (2.83). Would the correlation improve?
Would the simulations decrease in quality if you altered the E255K growth rates and tried to make corrections off of those? This is kind of like a negative control for corrections.
